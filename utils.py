#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAG Agent å·¥å…·å‡½æ•°æ¨¡å—
æä¾›é€šç”¨çš„è¾…åŠ©åŠŸèƒ½
"""

import os
import re
import time
import hashlib
import json
from pathlib import Path
from typing import List, Dict, Any, Optional, Union, Tuple
from datetime import datetime, timedelta
from functools import wraps
from loguru import logger


def timer(func):
    """
    è®¡æ—¶è£…é¥°å™¨
    
    Args:
        func: è¢«è£…é¥°çš„å‡½æ•°
    
    Returns:
        è£…é¥°åçš„å‡½æ•°
    """
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        execution_time = end_time - start_time
        logger.debug(f"{func.__name__} æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’")
        return result
    return wrapper


def retry(max_attempts: int = 3, delay: float = 1.0, backoff: float = 2.0):
    """
    é‡è¯•è£…é¥°å™¨
    
    Args:
        max_attempts: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: åˆå§‹å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
        backoff: å»¶è¿Ÿå€æ•°
    
    Returns:
        è£…é¥°å™¨å‡½æ•°
    """
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            current_delay = delay
            last_exception = None
            
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    if attempt < max_attempts - 1:
                        logger.warning(
                            f"{func.__name__} ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}, "
                            f"{current_delay:.1f}ç§’åé‡è¯•"
                        )
                        time.sleep(current_delay)
                        current_delay *= backoff
                    else:
                        logger.error(f"{func.__name__} æ‰€æœ‰é‡è¯•å‡å¤±è´¥")
            
            raise last_exception
        return wrapper
    return decorator


def safe_execute(func, default=None, log_error: bool = True):
    """
    å®‰å…¨æ‰§è¡Œå‡½æ•°ï¼Œæ•è·å¼‚å¸¸å¹¶è¿”å›é»˜è®¤å€¼
    
    Args:
        func: è¦æ‰§è¡Œçš„å‡½æ•°
        default: å¼‚å¸¸æ—¶è¿”å›çš„é»˜è®¤å€¼
        log_error: æ˜¯å¦è®°å½•é”™è¯¯æ—¥å¿—
    
    Returns:
        å‡½æ•°æ‰§è¡Œç»“æœæˆ–é»˜è®¤å€¼
    """
    try:
        return func()
    except Exception as e:
        if log_error:
            logger.error(f"å‡½æ•°æ‰§è¡Œå¤±è´¥: {e}")
        return default


def calculate_file_hash(file_path: Union[str, Path], algorithm: str = "md5") -> str:
    """
    è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        algorithm: å“ˆå¸Œç®—æ³•ï¼ˆmd5, sha1, sha256ï¼‰
    
    Returns:
        str: æ–‡ä»¶å“ˆå¸Œå€¼
    """
    file_path = Path(file_path)
    if not file_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    hash_obj = hashlib.new(algorithm)
    
    with open(file_path, 'rb') as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_obj.update(chunk)
    
    return hash_obj.hexdigest()


def calculate_text_hash(text: str, algorithm: str = "md5") -> str:
    """
    è®¡ç®—æ–‡æœ¬å“ˆå¸Œå€¼
    
    Args:
        text: æ–‡æœ¬å†…å®¹
        algorithm: å“ˆå¸Œç®—æ³•
    
    Returns:
        str: æ–‡æœ¬å“ˆå¸Œå€¼
    """
    hash_obj = hashlib.new(algorithm)
    hash_obj.update(text.encode('utf-8'))
    return hash_obj.hexdigest()


def format_file_size(size_bytes: int) -> str:
    """
    æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
    
    Args:
        size_bytes: å­—èŠ‚æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„å¤§å°å­—ç¬¦ä¸²
    """
    if size_bytes == 0:
        return "0 B"
    
    size_names = ["B", "KB", "MB", "GB", "TB"]
    i = 0
    size = float(size_bytes)
    
    while size >= 1024.0 and i < len(size_names) - 1:
        size /= 1024.0
        i += 1
    
    return f"{size:.1f} {size_names[i]}"


def format_duration(seconds: float) -> str:
    """
    æ ¼å¼åŒ–æ—¶é—´é—´éš”
    
    Args:
        seconds: ç§’æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²
    """
    if seconds < 1:
        return f"{seconds*1000:.0f}ms"
    elif seconds < 60:
        return f"{seconds:.1f}s"
    elif seconds < 3600:
        minutes = int(seconds // 60)
        secs = int(seconds % 60)
        return f"{minutes}m{secs}s"
    else:
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        return f"{hours}h{minutes}m"


def clean_text(text: str) -> str:
    """
    æ¸…ç†æ–‡æœ¬å†…å®¹
    
    Args:
        text: åŸå§‹æ–‡æœ¬
    
    Returns:
        str: æ¸…ç†åçš„æ–‡æœ¬
    """
    if not text:
        return ""
    
    # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    text = re.sub(r'\s+', ' ', text)
    
    # ç§»é™¤é¦–å°¾ç©ºç™½
    text = text.strip()
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—ã€å¸¸ç”¨æ ‡ç‚¹ï¼‰
    text = re.sub(r'[^\u4e00-\u9fff\w\s.,!?;:()\[\]{}"\'-]', '', text)
    
    return text


def truncate_text(text: str, max_length: int, suffix: str = "...") -> str:
    """
    æˆªæ–­æ–‡æœ¬
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦
        suffix: æˆªæ–­åç¼€
    
    Returns:
        str: æˆªæ–­åçš„æ–‡æœ¬
    """
    if len(text) <= max_length:
        return text
    
    return text[:max_length - len(suffix)] + suffix


def extract_keywords(text: str, max_keywords: int = 10) -> List[str]:
    """
    æå–æ–‡æœ¬å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰
    
    Args:
        text: æ–‡æœ¬å†…å®¹
        max_keywords: æœ€å¤§å…³é”®è¯æ•°é‡
    
    Returns:
        List[str]: å…³é”®è¯åˆ—è¡¨
    """
    if not text:
        return []
    
    # ç®€å•çš„å…³é”®è¯æå–ï¼šåŸºäºè¯é¢‘
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    clean_text_content = re.sub(r'[^\u4e00-\u9fff\w\s]', ' ', text)
    
    # åˆ†è¯ï¼ˆç®€å•æŒ‰ç©ºæ ¼åˆ†å‰²ï¼‰
    words = clean_text_content.split()
    
    # è¿‡æ»¤çŸ­è¯å’Œå¸¸è§åœç”¨è¯
    stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±', 'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ', 'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰', 'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'}
    
    words = [word for word in words if len(word) > 1 and word not in stop_words]
    
    # ç»Ÿè®¡è¯é¢‘
    word_freq = {}
    for word in words:
        word_freq[word] = word_freq.get(word, 0) + 1
    
    # æŒ‰é¢‘ç‡æ’åº
    sorted_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
    
    # è¿”å›å‰Nä¸ªå…³é”®è¯
    return [word for word, freq in sorted_words[:max_keywords]]


def validate_file_path(file_path: Union[str, Path], must_exist: bool = True) -> Path:
    """
    éªŒè¯æ–‡ä»¶è·¯å¾„
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        must_exist: æ˜¯å¦å¿…é¡»å­˜åœ¨
    
    Returns:
        Path: éªŒè¯åçš„è·¯å¾„å¯¹è±¡
    
    Raises:
        ValueError: è·¯å¾„æ— æ•ˆ
        FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨ï¼ˆå½“must_exist=Trueæ—¶ï¼‰
    """
    if not file_path:
        raise ValueError("æ–‡ä»¶è·¯å¾„ä¸èƒ½ä¸ºç©º")
    
    path = Path(file_path).resolve()
    
    if must_exist and not path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {path}")
    
    return path


def ensure_directory(dir_path: Union[str, Path]) -> Path:
    """
    ç¡®ä¿ç›®å½•å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»º
    
    Args:
        dir_path: ç›®å½•è·¯å¾„
    
    Returns:
        Path: ç›®å½•è·¯å¾„å¯¹è±¡
    """
    path = Path(dir_path).resolve()
    path.mkdir(parents=True, exist_ok=True)
    return path


def load_json_file(file_path: Union[str, Path], default: Any = None) -> Any:
    """
    åŠ è½½JSONæ–‡ä»¶
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
        default: åŠ è½½å¤±è´¥æ—¶çš„é»˜è®¤å€¼
    
    Returns:
        JSONæ•°æ®æˆ–é»˜è®¤å€¼
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.warning(f"åŠ è½½JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return default


def save_json_file(data: Any, file_path: Union[str, Path], indent: int = 2) -> bool:
    """
    ä¿å­˜JSONæ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        file_path: æ–‡ä»¶è·¯å¾„
        indent: ç¼©è¿›ç©ºæ ¼æ•°
    
    Returns:
        bool: æ˜¯å¦ä¿å­˜æˆåŠŸ
    """
    try:
        file_path = Path(file_path)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=indent)
        
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        return False


def get_file_stats(file_path: Union[str, Path]) -> Dict[str, Any]:
    """
    è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„
    
    Returns:
        Dict[str, Any]: æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
    """
    path = Path(file_path)
    
    if not path.exists():
        return {}
    
    stat = path.stat()
    
    return {
        'size': stat.st_size,
        'size_formatted': format_file_size(stat.st_size),
        'created': datetime.fromtimestamp(stat.st_ctime),
        'modified': datetime.fromtimestamp(stat.st_mtime),
        'accessed': datetime.fromtimestamp(stat.st_atime),
        'is_file': path.is_file(),
        'is_dir': path.is_dir(),
        'extension': path.suffix.lower(),
        'name': path.name,
        'stem': path.stem
    }


def find_files(directory: Union[str, Path], 
               pattern: str = "*", 
               recursive: bool = True,
               include_dirs: bool = False) -> List[Path]:
    """
    æŸ¥æ‰¾æ–‡ä»¶
    
    Args:
        directory: æœç´¢ç›®å½•
        pattern: æ–‡ä»¶æ¨¡å¼
        recursive: æ˜¯å¦é€’å½’æœç´¢
        include_dirs: æ˜¯å¦åŒ…å«ç›®å½•
    
    Returns:
        List[Path]: æ‰¾åˆ°çš„æ–‡ä»¶åˆ—è¡¨
    """
    directory = Path(directory)
    
    if not directory.exists():
        return []
    
    if recursive:
        files = directory.rglob(pattern)
    else:
        files = directory.glob(pattern)
    
    result = []
    for file in files:
        if include_dirs or file.is_file():
            result.append(file)
    
    return sorted(result)


def create_progress_bar(current: int, total: int, width: int = 50) -> str:
    """
    åˆ›å»ºè¿›åº¦æ¡å­—ç¬¦ä¸²
    
    Args:
        current: å½“å‰è¿›åº¦
        total: æ€»æ•°
        width: è¿›åº¦æ¡å®½åº¦
    
    Returns:
        str: è¿›åº¦æ¡å­—ç¬¦ä¸²
    """
    if total == 0:
        return "[" + "="*width + "] 100%"
    
    percentage = min(100, int((current / total) * 100))
    filled = int((current / total) * width)
    bar = "=" * filled + "-" * (width - filled)
    
    return f"[{bar}] {percentage}% ({current}/{total})"


def normalize_query(query: str) -> str:
    """
    æ ‡å‡†åŒ–æŸ¥è¯¢å­—ç¬¦ä¸²
    
    Args:
        query: åŸå§‹æŸ¥è¯¢
    
    Returns:
        str: æ ‡å‡†åŒ–åçš„æŸ¥è¯¢
    """
    if not query:
        return ""
    
    # è½¬æ¢ä¸ºå°å†™
    query = query.lower()
    
    # ç§»é™¤å¤šä½™ç©ºç™½
    query = re.sub(r'\s+', ' ', query)
    
    # ç§»é™¤é¦–å°¾ç©ºç™½
    query = query.strip()
    
    return query


def split_text_by_sentences(text: str, max_length: int = 1000) -> List[str]:
    """
    æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬ï¼Œç¡®ä¿æ¯æ®µä¸è¶…è¿‡æœ€å¤§é•¿åº¦
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_length: æœ€å¤§é•¿åº¦
    
    Returns:
        List[str]: åˆ†å‰²åçš„æ–‡æœ¬æ®µè½
    """
    if not text:
        return []
    
    # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ.!?]', text)
    
    result = []
    current_chunk = ""
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        # å¦‚æœå½“å‰å¥å­æœ¬èº«å°±è¶…è¿‡æœ€å¤§é•¿åº¦ï¼Œå¼ºåˆ¶åˆ†å‰²
        if len(sentence) > max_length:
            if current_chunk:
                result.append(current_chunk)
                current_chunk = ""
            
            # æŒ‰å­—ç¬¦å¼ºåˆ¶åˆ†å‰²é•¿å¥å­
            for i in range(0, len(sentence), max_length):
                result.append(sentence[i:i + max_length])
        else:
            # æ£€æŸ¥æ·»åŠ å½“å‰å¥å­æ˜¯å¦ä¼šè¶…è¿‡é•¿åº¦é™åˆ¶
            if len(current_chunk) + len(sentence) + 1 > max_length:
                if current_chunk:
                    result.append(current_chunk)
                current_chunk = sentence
            else:
                if current_chunk:
                    current_chunk += " " + sentence
                else:
                    current_chunk = sentence
    
    # æ·»åŠ æœ€åä¸€ä¸ªåˆ†å—
    if current_chunk:
        result.append(current_chunk)
    
    return result


def calculate_similarity_score(text1: str, text2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰
    
    Args:
        text1: æ–‡æœ¬1
        text2: æ–‡æœ¬2
    
    Returns:
        float: ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆ0-1ï¼‰
    """
    if not text1 or not text2:
        return 0.0
    
    # ç®€å•çš„åŸºäºè¯æ±‡é‡å çš„ç›¸ä¼¼åº¦è®¡ç®—
    words1 = set(text1.lower().split())
    words2 = set(text2.lower().split())
    
    if not words1 or not words2:
        return 0.0
    
    intersection = words1.intersection(words2)
    union = words1.union(words2)
    
    return len(intersection) / len(union) if union else 0.0


class PerformanceMonitor:
    """
    æ€§èƒ½ç›‘æ§å™¨
    """
    
    def __init__(self):
        self.metrics = {}
        self.start_times = {}
    
    def start_timer(self, name: str) -> None:
        """
        å¼€å§‹è®¡æ—¶
        
        Args:
            name: è®¡æ—¶å™¨åç§°
        """
        self.start_times[name] = time.time()
    
    def end_timer(self, name: str) -> float:
        """
        ç»“æŸè®¡æ—¶
        
        Args:
            name: è®¡æ—¶å™¨åç§°
        
        Returns:
            float: æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        """
        if name not in self.start_times:
            return 0.0
        
        duration = time.time() - self.start_times[name]
        
        if name not in self.metrics:
            self.metrics[name] = []
        
        self.metrics[name].append(duration)
        del self.start_times[name]
        
        return duration
    
    def get_stats(self, name: str) -> Dict[str, float]:
        """
        è·å–ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            name: è®¡æ—¶å™¨åç§°
        
        Returns:
            Dict[str, float]: ç»Ÿè®¡ä¿¡æ¯
        """
        if name not in self.metrics or not self.metrics[name]:
            return {}
        
        times = self.metrics[name]
        
        return {
            'count': len(times),
            'total': sum(times),
            'average': sum(times) / len(times),
            'min': min(times),
            'max': max(times)
        }
    
    def get_all_stats(self) -> Dict[str, Dict[str, float]]:
        """
        è·å–æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, Dict[str, float]]: æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
        """
        return {name: self.get_stats(name) for name in self.metrics}
    
    def reset(self) -> None:
        """
        é‡ç½®æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
        """
        self.metrics.clear()
        self.start_times.clear()


# å…¨å±€æ€§èƒ½ç›‘æ§å™¨å®ä¾‹
performance_monitor = PerformanceMonitor()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    print("ğŸ§ª æµ‹è¯•å·¥å…·å‡½æ•°...")
    
    # æµ‹è¯•æ–‡æœ¬å¤„ç†
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ã€‚å®ƒåŒ…å«å¤šä¸ªå¥å­ï¼è¿˜æœ‰ä¸€äº›ç‰¹æ®Šå­—ç¬¦@#$%ã€‚"
    print(f"åŸæ–‡æœ¬: {test_text}")
    print(f"æ¸…ç†å: {clean_text(test_text)}")
    print(f"å…³é”®è¯: {extract_keywords(test_text)}")
    
    # æµ‹è¯•æ—¶é—´æ ¼å¼åŒ–
    print(f"\næ—¶é—´æ ¼å¼åŒ–æµ‹è¯•:")
    print(f"0.5ç§’: {format_duration(0.5)}")
    print(f"65ç§’: {format_duration(65)}")
    print(f"3661ç§’: {format_duration(3661)}")
    
    # æµ‹è¯•æ–‡ä»¶å¤§å°æ ¼å¼åŒ–
    print(f"\næ–‡ä»¶å¤§å°æ ¼å¼åŒ–æµ‹è¯•:")
    print(f"1024å­—èŠ‚: {format_file_size(1024)}")
    print(f"1048576å­—èŠ‚: {format_file_size(1048576)}")
    
    # æµ‹è¯•è¿›åº¦æ¡
    print(f"\nè¿›åº¦æ¡æµ‹è¯•:")
    print(create_progress_bar(25, 100))
    print(create_progress_bar(50, 100))
    print(create_progress_bar(100, 100))
    
    print("\nâœ… å·¥å…·å‡½æ•°æµ‹è¯•å®Œæˆ")